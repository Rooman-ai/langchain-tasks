# LangChain Summarization Project
A project to master LangChain through structured tasks.
Contributor: - Rooman

Task-1:
This task loads environment variables from a .env file using the dotenv library, retrieves Azure OpenAI configuration values (API key, endpoint, deployment name, and API version) from the environment, and prints them to the console.

Task-2:
This task imports two utility functions: one to configure an OpenAI language model and another to build a text summarizer. It sets up the language model, defines a passage about artificial intelligence, and creates two summarizersâ€”one for a three-sentence summary and one for a single-sentence summary. It then prints both summaries of the AI passage using the respective summarizers.

Task-3:
This task loads a text file about AI, splits it into chunks, and stores their embeddings for retrieval. It then queries the vector store for text relevant to "AI milestones," summarizes the retrieved text into three sentences and one sentence using an LLM-based summarizer, and prints both summaries.

Task-4:
This task sets up an OpenAI language model and builds a three-sentence summarizer chain. It wraps the summarizer as a tool, adds it to an agent, and then uses the agent to summarize a passage about AI's impact on healthcare and to handle a vague summarization request. The results are printed to the console.

Task-5:
This task sets up an agent with tools for retrieving relevant text, summarizing it, and counting words. It loads a document, splits it into chunks, and creates embeddings. The agent is then used to find and summarize text about AI breakthroughs, and also to find, summarize, and count the words in the summary. The results are printed to the console.

Task-6:
This script demonstrates how to use LangChain's conversation memory modules to summarize and maintain context across multiple text inputs about machine learning and deep learning, printing summaries with both buffer and summary memory approaches.

Task-7:
This task demonstrates how to use LangChain to process and summarize information from both a PDF document and a web page about AI challenges. It begins by configuring an OpenAI language model and embedding model, then loads the content of a specified PDF file and a web page using PyPDFLoader and WebBaseLoader, respectively. The loaded documents are split into manageable text chunks and stored as vector embeddings for efficient retrieval. The script then formulates a query ("AI challenges") and retrieves the most relevant text segments from both the PDF and web content using a retriever function. Finally, it uses a summarizer chain built on the language model to generate three-sentence summaries of the retrieved content from each source, printing the results for both the PDF and the web page. This approach enables efficient extraction and summarization of targeted information from diverse document types

Task 8:
This task leverages LangChain's prompt templates and structured output parsing to summarize a detailed passage about the impact of artificial intelligence across multiple industries into three sentences, calculates the character count of the summary, and outputs the result as a JSON object.

Task 9:
This script loads a text file about AI, creates vector embeddings, and uses both a standard retriever and LangChain's MultiQueryRetriever to find and summarize relevant content about "AI advancements," printing summaries for both single and multiple query approaches.